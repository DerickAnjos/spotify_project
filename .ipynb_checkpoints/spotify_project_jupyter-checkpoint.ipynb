{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4804723",
   "metadata": {},
   "source": [
    "# Spotify charts - Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d936af68",
   "metadata": {},
   "source": [
    "## Preparing PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dfd01a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyspark==3.2.1 in c:\\users\\derick\\appdata\\roaming\\python\\python310\\site-packages (3.2.1)\n",
      "Requirement already satisfied: py4j==0.10.9.3 in c:\\users\\derick\\appdata\\roaming\\python\\python310\\site-packages (from pyspark==3.2.1) (0.10.9.3)\n"
     ]
    }
   ],
   "source": [
    "# Installing and importing packages\n",
    "\n",
    "!pip install pyspark==3.2.1\n",
    "import pyspark\n",
    "import pandas as pd\n",
    "\n",
    "# Importing important classes of Spark SQL and DataFrames\n",
    "\n",
    "from pyspark.sql import SparkSession # Main entry point for DataFrame and SQL functionality\n",
    "import pyspark.sql.types as t # List of data types avaiable\n",
    "import pyspark.sql.functions as f # List of built-in functions avaiable for DataFrame \n",
    "from pyspark.sql.functions import date_format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3febe7d8",
   "metadata": {},
   "source": [
    "In this project, we're going to use Spark (large dataset, with more than 28 milions lines) and SQL to explore the dataset.\n",
    "\n",
    "The first step working with Spark, is create a instance of class \"Spark Session\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ba88960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a Spark session - entry point to underlying Spark funtionality\n",
    "spark = (SparkSession.builder.config(\"spark.driver.memory\",\"4g\").config(\"spark.driver.maxResultSize\", \"4g\").getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea2ea09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dataset (with spark)\n",
    "data_spk = spark.read.csv(path = 'charts.csv', inferSchema = True, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff8cf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking into the data types, all of then are 'string'. We need to use the correct type to perform our analysis.\n",
    "# This are the data types supported by Spark DataFrames and SQL: https://spark.apache.org/docs/latest/sql-ref-datatypes.html\n",
    "data_spk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ec9f8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicating column 'date', to use two different date formats\n",
    "data_spk = data_spk.withColumn('date_complete', data_spk.date)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "aca83fad",
   "metadata": {},
   "source": [
    "Setting the appropriate data types and transforming column \"date\" from \"yyyy-mm-dd\" to \"yyyy-mm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f5f4fbd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Apllying data typ\n",
    "data_spk = data_spk.withColumn('rank', f.col('rank').cast(t.IntegerType())).withColumn('date', f.col('date').cast(t.DateType())).withColumn('date', date_format(f.col(\"date\"), \"yyyy-MM\").alias(\"date_format\")).withColumn('streams', f.col('streams').cast(t.IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881b9e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifying the data types of 'rank', 'date' and 'streams'\n",
    "data_spk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac998388",
   "metadata": {},
   "source": [
    "To save our intermediare queries and results, we create a temp table (process data much faster).\n",
    "It's important understand that temporary tables are available just within the current session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98dd03d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Derick\\AppData\\Roaming\\Python\\Python310\\site-packages\\pyspark\\sql\\dataframe.py:138: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Setting a temp table\n",
    "data_spk.registerTempTable('data_temp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11c2ee9",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis with PySpark - SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb12757b",
   "metadata": {},
   "source": [
    "**Period of analysis - Spotify Charts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06350303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>begin</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01</td>\n",
       "      <td>2021-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     begin      end\n",
       "0  2017-01  2021-12"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql('''\n",
    "SELECT MIN(date) begin, MAX(date) end \n",
    "FROM data_temp \n",
    "WHERE chart = 'top200';\n",
    "''').toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2194848c",
   "metadata": {},
   "source": [
    "## Artists analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46df57ea",
   "metadata": {},
   "source": [
    "**Artist with most different tracks on Top 200 - by day**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93a253d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_tracks_appear_day = spark.sql('''\n",
    "WITH CTE AS\n",
    "(\n",
    "    WITH CTE2 AS \n",
    "    (\n",
    "        SELECT artist, region, date_complete as date, count(DISTINCT title) as n\n",
    "        FROM data_temp \n",
    "        WHERE chart = 'top200'\n",
    "        GROUP BY region, date_complete, artist\n",
    "        ORDER BY n DESC\n",
    "    )\n",
    "    SELECT artist, region, n, date, ROW_NUMBER() OVER (PARTITION BY region, date Order by n DESC) AS Rank FROM CTE2 \n",
    ")\n",
    "SELECT * FROM CTE WHERE Rank <= 10;\n",
    "''').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418e418b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the dataset as a csv file\n",
    "artist_tracks_appear_day.to_csv('data_tableau/artist_tracks_appear_day.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efb3fab",
   "metadata": {},
   "source": [
    "**Artist with most different tracks on Top 200 - by month**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0dcea764",
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_tracks_appear_month = spark.sql('''\n",
    "WITH CTE AS\n",
    "(\n",
    "    WITH CTE2 AS \n",
    "    (\n",
    "        SELECT artist, region, date, count(DISTINCT title) as n\n",
    "        FROM data_temp \n",
    "        WHERE chart = 'top200'\n",
    "        GROUP BY region, date, artist\n",
    "        ORDER BY n DESC\n",
    "    )\n",
    "    SELECT artist, region, n, date, ROW_NUMBER() OVER (PARTITION BY region, date Order by n DESC) AS Rank FROM CTE2 \n",
    ")\n",
    "SELECT * FROM CTE WHERE Rank <= 10;\n",
    "''').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4822779a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the dataset as a csv file\n",
    "artist_tracks_appear_month.to_csv('data_tableau/artist_tracks_appear_month.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a1cc0d",
   "metadata": {},
   "source": [
    "**Artist with most different tracks on Top 200 - by year**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3149fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_tracks_appear_year = spark.sql('''\n",
    "WITH CTE AS\n",
    "(\n",
    "    WITH CTE2 AS \n",
    "    (\n",
    "        SELECT artist, region, YEAR(date) as year, count(DISTINCT title) as n\n",
    "        FROM data_temp \n",
    "        WHERE chart = 'top200'\n",
    "        GROUP BY region, artist, YEAR(date)\n",
    "        ORDER BY n DESC\n",
    "    )\n",
    "    SELECT artist, region, n, year, ROW_NUMBER() OVER (PARTITION BY region, year Order by n DESC) AS Rank FROM CTE2 \n",
    ")\n",
    "SELECT * FROM CTE WHERE Rank <= 10;\n",
    "''').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f2a3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the dataset as a csv file\n",
    "artist_tracks_appear_year.to_csv('data_tableau/artist_tracks_appear_year.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14b200b",
   "metadata": {},
   "source": [
    "**Artist appearances on Top 200 - by year**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36916c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_appear_year = spark.sql('''\n",
    "WITH CTE AS\n",
    "(\n",
    "    WITH CTE2 AS \n",
    "    (\n",
    "        SELECT artist, region, YEAR(date) as year, count(artist) as n\n",
    "        FROM data_temp \n",
    "        WHERE chart = 'top200'\n",
    "        GROUP BY artist, YEAR(date), region\n",
    "        ORDER BY n DESC\n",
    "    )\n",
    "    SELECT artist, region, n, year, ROW_NUMBER() OVER (PARTITION BY region, year Order by n DESC) AS Rank FROM CTE2 \n",
    ")\n",
    "SELECT * FROM CTE WHERE Rank <= 10;\n",
    "''').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87e6f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the dataset as a csv file\n",
    "artist_appear_year.to_csv('data_tableau/artist_appear_year.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a05d5d",
   "metadata": {},
   "source": [
    "**Artist with the most number of music streams - by year (1 stream  = 1 song that has been played over 30 sec)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a3e5632",
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_stream_year = spark.sql('''\n",
    "WITH CTE AS\n",
    "(\n",
    "    WITH CTE2 AS \n",
    "    (\n",
    "        SELECT artist, region, YEAR(date) as year, sum(streams) as stream\n",
    "        FROM data_temp \n",
    "        WHERE chart = 'top200'\n",
    "        GROUP BY artist, region, YEAR(date)\n",
    "        ORDER BY stream DESC\n",
    "    )\n",
    "    SELECT artist, region, stream, year, ROW_NUMBER() OVER (PARTITION BY region, year Order by stream DESC) AS Rank FROM CTE2 \n",
    ")\n",
    "SELECT * FROM CTE WHERE Rank <= 10;\n",
    "''').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7fab60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the dataset as a csv file\n",
    "artist_stream_year.to_csv('data_tableau/artist_stream_year.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077ebab0",
   "metadata": {},
   "source": [
    "**Artists to achieve Top 1 the most times**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d70c8279",
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_first_rank = spark.sql('''\n",
    "SELECT artist, region, YEAR(date) as date, count(artist) as n\n",
    "FROM data_temp\n",
    "WHERE chart = 'top200'\n",
    "AND rank = 1\n",
    "GROUP BY artist, region, YEAR(date)\n",
    "ORDER BY n DESC\n",
    "''').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb86c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the dataset as a csv file\n",
    "artist_first_rank.to_csv('data_tableau/artist_first_rank.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea28222",
   "metadata": {},
   "source": [
    "**Artists to achieve Top 1 the most times (region independent)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5577e0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_first_rank_indep_region = spark.sql('''\n",
    "SELECT artist, date, count(artist) as n\n",
    "FROM data_temp\n",
    "WHERE chart = 'top200'\n",
    "AND rank = 1\n",
    "AND region <> \"Global\"\n",
    "GROUP BY artist, date\n",
    "ORDER BY n DESC\n",
    "''').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffaa812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the dataset as a csv file\n",
    "artist_first_rank_indep_region.to_csv('data_tableau/artist_first_rank_indep_region.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2ef05e",
   "metadata": {},
   "source": [
    "## Song analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aedb4de",
   "metadata": {},
   "source": [
    "**Songs with the most appearances by year**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "af60df25",
   "metadata": {},
   "outputs": [],
   "source": [
    "song_appear_year = spark.sql('''\n",
    "WITH CTE AS\n",
    "(\n",
    "    WITH CTE2 AS \n",
    "    (\n",
    "        SELECT title, artist, region, YEAR(date) as year, count(title) as n\n",
    "        FROM data_temp \n",
    "        WHERE chart = 'top200'\n",
    "        GROUP BY title, artist, region, YEAR(date)\n",
    "        ORDER BY n DESC\n",
    "    )\n",
    "    SELECT title, artist, region, year, n, ROW_NUMBER() OVER (PARTITION BY region, year Order by n DESC) AS Rank FROM CTE2 \n",
    ")\n",
    "SELECT * FROM CTE WHERE Rank <= 20;\n",
    "''').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc5d44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the dataset as a csv file\n",
    "song_appear_year.to_csv('data_tableau/song_appear_year.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5e4968",
   "metadata": {},
   "source": [
    "**Songs with the most number of streams on single year**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d80b59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "song_stream_year = spark.sql('''\n",
    "WITH CTE AS\n",
    "(\n",
    "    WITH CTE2 AS \n",
    "    (\n",
    "        SELECT title, artist, region, YEAR(date) as year, sum(streams) as stream\n",
    "        FROM data_temp \n",
    "        WHERE chart = 'top200'\n",
    "        GROUP BY title, artist, region, YEAR(date)\n",
    "        ORDER BY stream DESC\n",
    "    )\n",
    "    SELECT title, artist, region, year, stream, ROW_NUMBER() OVER (PARTITION BY region, year Order by stream DESC) AS Rank FROM CTE2 \n",
    ")\n",
    "SELECT * FROM CTE WHERE Rank <= 10;\n",
    "''').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f4d533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the dataset as a csv file\n",
    "song_stream_year.to_csv('data_tableau/song_stream_year.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a064fbac",
   "metadata": {},
   "source": [
    "**Songs with the most number of streams on single month**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a20510f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "song_stream_month = spark.sql('''\n",
    "WITH CTE AS\n",
    "(\n",
    "    WITH CTE2 AS \n",
    "    (\n",
    "        SELECT title, artist, region, date, sum(streams) as stream\n",
    "        FROM data_temp \n",
    "        WHERE chart = 'top200'\n",
    "        GROUP BY title, artist, region, date\n",
    "        ORDER BY stream DESC\n",
    "    )\n",
    "    SELECT title, artist, region, date, stream, ROW_NUMBER() OVER (PARTITION BY region, date Order by stream DESC) AS Rank FROM CTE2 \n",
    ")\n",
    "SELECT * FROM CTE WHERE Rank <= 10;\n",
    "''').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2154368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the dataset as a csv file\n",
    "song_stream_month.to_csv('data_tableau/song_stream_month.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416d0eb4",
   "metadata": {},
   "source": [
    "**Songs with the most number of streams on a single day**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8470bf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "song_stream_day = spark.sql('''\n",
    "WITH CTE AS\n",
    "(\n",
    "    WITH CTE2 AS \n",
    "    (\n",
    "        SELECT  title, artist, region, sum(streams) as stream, date_complete as date\n",
    "        FROM data_temp \n",
    "        WHERE chart = 'top200'\n",
    "        GROUP BY date_complete, title, artist, region\n",
    "        ORDER BY stream DESC\n",
    "    )\n",
    "    SELECT title, artist, region, stream, date, ROW_NUMBER() OVER (PARTITION BY region, date Order by stream DESC) AS Rank FROM CTE2 \n",
    ")\n",
    "SELECT * FROM CTE WHERE Rank <= 10;\n",
    "''').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a604be79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the dataset as a csv file\n",
    "song_stream_day.to_csv('data_tableau/song_stream_day.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c5e8e7",
   "metadata": {},
   "source": [
    "**Songs that stayed at Top 1 the most times**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "df2557b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_first_rank = spark.sql('''\n",
    "SELECT  title, artist, region, date, count(title) as n\n",
    "FROM data_temp \n",
    "WHERE chart = 'top200'\n",
    "AND rank = 1\n",
    "GROUP BY title, artist, region, date\n",
    "ORDER BY n DESC;\n",
    "''').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff95235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the dataset as a csv file\n",
    "songs_first_rank.to_csv('data_tableau/songs_first_rank.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7657a0",
   "metadata": {},
   "source": [
    "**Songs that stayed at Top 1 the most times (region independent)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b79d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_first_rank_indep_region = spark.sql('''\n",
    "SELECT  title, artist, date, count(title) as n\n",
    "FROM data_temp \n",
    "WHERE chart = 'top200'\n",
    "AND rank = 1\n",
    "AND region <> 'Global'\n",
    "GROUP BY title, artist, date\n",
    "ORDER BY n DESC;\n",
    "''').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15912537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the dataset as a csv file\n",
    "songs_first_rank_indep_region.to_csv('data_tableau/songs_first_rank_indep_region.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5863d35d",
   "metadata": {},
   "source": [
    "**KPI - Streams/population (map plot)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "541b01f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "streams_population = spark.sql('''\n",
    "SELECT region, YEAR(date), sum(streams) as stream\n",
    "FROM data_temp\n",
    "WHERE chart = 'top200'\n",
    "AND region <> \"Global\"\n",
    "GROUP BY region, YEAR(date)\n",
    "ORDER BY stream DESC\n",
    "''').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8579c1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uploading a dataset with values of the population of each country\n",
    "country_population = pd.read_excel('country_population.xlsx', dtype = {'Country Name': str, 'Population': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d4a71201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing variable names\n",
    "country_population = country_population.rename(columns={'Country Name':'region', 'Population':'population'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "44648885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying left join on both dataframes\n",
    "streams_population = pd.merge(streams_population, country_population, on = 'region', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "815b8ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>year(date)</th>\n",
       "      <th>stream</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United States</td>\n",
       "      <td>2018</td>\n",
       "      <td>30785180823</td>\n",
       "      <td>331893745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United States</td>\n",
       "      <td>2019</td>\n",
       "      <td>29791300658</td>\n",
       "      <td>331893745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>United States</td>\n",
       "      <td>2020</td>\n",
       "      <td>28685986160</td>\n",
       "      <td>331893745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>United States</td>\n",
       "      <td>2021</td>\n",
       "      <td>27093009816</td>\n",
       "      <td>331893745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>United States</td>\n",
       "      <td>2017</td>\n",
       "      <td>25763351668</td>\n",
       "      <td>331893745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Brazil</td>\n",
       "      <td>2021</td>\n",
       "      <td>16426316020</td>\n",
       "      <td>214326223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Brazil</td>\n",
       "      <td>2020</td>\n",
       "      <td>12523039097</td>\n",
       "      <td>214326223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mexico</td>\n",
       "      <td>2020</td>\n",
       "      <td>11678777603</td>\n",
       "      <td>126705138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mexico</td>\n",
       "      <td>2021</td>\n",
       "      <td>11229884263</td>\n",
       "      <td>126705138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Brazil</td>\n",
       "      <td>2019</td>\n",
       "      <td>11105842661</td>\n",
       "      <td>214326223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          region  year(date)       stream population\n",
       "0  United States        2018  30785180823  331893745\n",
       "1  United States        2019  29791300658  331893745\n",
       "2  United States        2020  28685986160  331893745\n",
       "3  United States        2021  27093009816  331893745\n",
       "4  United States        2017  25763351668  331893745\n",
       "5         Brazil        2021  16426316020  214326223\n",
       "6         Brazil        2020  12523039097  214326223\n",
       "7         Mexico        2020  11678777603  126705138\n",
       "8         Mexico        2021  11229884263  126705138\n",
       "9         Brazil        2019  11105842661  214326223"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streams_population.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a82d002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the dataset as a csv file\n",
    "streams_population.to_csv('data_tableau/streams_population.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
